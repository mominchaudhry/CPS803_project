{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(verbose=False):\n",
    "    rootDir = 'Images'\n",
    "    images = np.zeros((1, 1280), dtype=np.uint8)\n",
    "    labels = np.empty(20580, dtype=object)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    sift = cv2.SIFT_create(10)\n",
    "    for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "        #print('Found directory: %s' % dirName)\n",
    "        if dirName != 'Images':\n",
    "            l = dirName.split('-')\n",
    "            label = l[1]\n",
    "#             if j == 5:\n",
    "#                 break\n",
    "            j += 1\n",
    "            print(label, j)\n",
    "        count = 0\n",
    "        for fname in fileList:\n",
    "            if dirName != 'Images':\n",
    "                img = cv2.imread(dirName + '/' + fname, 0)\n",
    "                file = open(\"Annotation\\\\\" + dirName.replace('Images\\\\', '') + \"\\\\\" + fname.replace('.jpg', '')).read()\n",
    "                bnd = [s.strip() for s in re.findall(r'<bndbox>(.*)</bndbox>', file, re.DOTALL)][0].replace('<', ' ').replace('>', ' ').split()\n",
    "                bndbox = [bnd[1], bnd[4], bnd[7], bnd[10]]\n",
    "                im3 = img[int(bndbox[1]):int(bndbox[3]), int(bndbox[0]):int(bndbox[2])]\n",
    "                if verbose == True:\n",
    "                    print(fname, i)\n",
    "                #im = cv2.resize(im3, dsize=(256, 256), interpolation=cv2.INTER_CUBIC).astype(np.uint8)\n",
    "                kp, des = sift.detectAndCompute(im3,None)\n",
    "#                 winSize = (64,64)\n",
    "#                 blockSize = (16,16)\n",
    "#                 blockStride = (8,8)\n",
    "#                 cellSize = (8,8)\n",
    "#                 nbins = 9\n",
    "#                 derivAperture = 1\n",
    "#                 winSigma = 4.\n",
    "#                 histogramNormType = 0\n",
    "#                 L2HysThreshold = 2.0000000000000001e-01\n",
    "#                 gammaCorrection = 0\n",
    "#                 nlevels = 64\n",
    "#                 hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "#                                         histogramNormType,L2HysThreshold,gammaCorrection,nlevels)\n",
    "#                 winStride = (8,8)\n",
    "#                 padding = (8,8)\n",
    "#                 locations = ((10,20),)\n",
    "#                 hist = hog.compute(im,winStride,padding,locations)\n",
    "                imm = des[:10,:].flatten().reshape(1, 1280)\n",
    "                images = np.append(images, imm, axis=0)\n",
    "                labels[i] = label\n",
    "                i += 1\n",
    "#                 if count >= 99:\n",
    "#                     break\n",
    "#                 count += 1\n",
    "    return images[1:,:], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images, Labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Images.shape)\n",
    "# print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, test_x, train_y, test_y = train_test_split(Images, Labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.shape, train_y.shape)\n",
    "# print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "mat = loadmat('train_data.mat')\n",
    "train_data = mat['train_data']\n",
    "train_labels = mat['train_info'][0, 0]['labels'].reshape(12000, )\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='precomputed')\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = loadmat('test_data.mat')\n",
    "test_data = mat1['test_data']\n",
    "test_labels = mat1['test_info'][0, 0]['labels'].reshape(len(test_data), )\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test_data)\n",
    "print(preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, preds)\n",
    "np.savetxt('confusion.txt', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "CNN BELOW\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "data = torchvision.datasets.ImageFolder(root='Images', transform=trans)\n",
    "traindata, testdata = torch.utils.data.random_split(data, [12000, 8580])\n",
    "print(traindata, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=4)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size = 4)\n",
    "print(trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 29*29, 240)\n",
    "        self.fc2 = nn.Linear(240, 120)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), 16*29*29)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 4.688\n",
      "[2,  2000] loss: 4.400\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 0 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 :  0 %\n",
      "Accuracy of     1 :  0 %\n",
      "Accuracy of     2 :  0 %\n",
      "Accuracy of     3 :  0 %\n",
      "Accuracy of     4 :  0 %\n",
      "Accuracy of     5 : 25 %\n",
      "Accuracy of     6 :  0 %\n",
      "Accuracy of     7 :  0 %\n",
      "Accuracy of     8 :  0 %\n",
      "Accuracy of     9 :  0 %\n",
      "Accuracy of    10 :  0 %\n",
      "Accuracy of    11 :  0 %\n",
      "Accuracy of    12 :  0 %\n",
      "Accuracy of    13 :  0 %\n",
      "Accuracy of    14 :  0 %\n",
      "Accuracy of    15 :  0 %\n",
      "Accuracy of    16 :  0 %\n",
      "Accuracy of    17 :  0 %\n",
      "Accuracy of    18 :  0 %\n",
      "Accuracy of    19 :  0 %\n",
      "Accuracy of    20 :  0 %\n",
      "Accuracy of    21 :  0 %\n",
      "Accuracy of    22 :  0 %\n",
      "Accuracy of    23 :  0 %\n",
      "Accuracy of    24 :  0 %\n",
      "Accuracy of    25 :  3 %\n",
      "Accuracy of    26 :  0 %\n",
      "Accuracy of    27 :  0 %\n",
      "Accuracy of    28 :  0 %\n",
      "Accuracy of    29 :  0 %\n",
      "Accuracy of    30 :  0 %\n",
      "Accuracy of    31 :  0 %\n",
      "Accuracy of    32 :  0 %\n",
      "Accuracy of    33 :  1 %\n",
      "Accuracy of    34 :  0 %\n",
      "Accuracy of    35 :  0 %\n",
      "Accuracy of    36 :  0 %\n",
      "Accuracy of    37 :  0 %\n",
      "Accuracy of    38 :  0 %\n",
      "Accuracy of    39 :  0 %\n",
      "Accuracy of    40 :  0 %\n",
      "Accuracy of    41 :  0 %\n",
      "Accuracy of    42 :  0 %\n",
      "Accuracy of    43 :  0 %\n",
      "Accuracy of    44 :  0 %\n",
      "Accuracy of    45 :  0 %\n",
      "Accuracy of    46 :  0 %\n",
      "Accuracy of    47 : 15 %\n",
      "Accuracy of    48 :  0 %\n",
      "Accuracy of    49 :  0 %\n",
      "Accuracy of    50 :  0 %\n",
      "Accuracy of    51 :  0 %\n",
      "Accuracy of    52 :  0 %\n",
      "Accuracy of    53 :  0 %\n",
      "Accuracy of    54 :  0 %\n",
      "Accuracy of    55 :  0 %\n",
      "Accuracy of    56 :  0 %\n",
      "Accuracy of    57 :  0 %\n",
      "Accuracy of    58 :  0 %\n",
      "Accuracy of    59 :  0 %\n",
      "Accuracy of    60 :  0 %\n",
      "Accuracy of    61 :  0 %\n",
      "Accuracy of    62 :  0 %\n",
      "Accuracy of    63 :  0 %\n",
      "Accuracy of    64 :  0 %\n",
      "Accuracy of    65 :  4 %\n",
      "Accuracy of    66 :  0 %\n",
      "Accuracy of    67 :  0 %\n",
      "Accuracy of    68 :  0 %\n",
      "Accuracy of    69 :  0 %\n",
      "Accuracy of    70 :  0 %\n",
      "Accuracy of    71 :  0 %\n",
      "Accuracy of    72 :  0 %\n",
      "Accuracy of    73 :  0 %\n",
      "Accuracy of    74 :  0 %\n",
      "Accuracy of    75 :  0 %\n",
      "Accuracy of    76 :  0 %\n",
      "Accuracy of    77 :  0 %\n",
      "Accuracy of    78 :  0 %\n",
      "Accuracy of    79 :  0 %\n",
      "Accuracy of    80 :  0 %\n",
      "Accuracy of    81 :  0 %\n",
      "Accuracy of    82 :  0 %\n",
      "Accuracy of    83 :  0 %\n",
      "Accuracy of    84 :  0 %\n",
      "Accuracy of    85 :  0 %\n",
      "Accuracy of    86 :  0 %\n",
      "Accuracy of    87 :  0 %\n",
      "Accuracy of    88 :  0 %\n",
      "Accuracy of    89 :  0 %\n",
      "Accuracy of    90 :  0 %\n",
      "Accuracy of    91 :  0 %\n",
      "Accuracy of    92 :  0 %\n",
      "Accuracy of    93 :  0 %\n",
      "Accuracy of    94 :  0 %\n",
      "Accuracy of    95 :  0 %\n",
      "Accuracy of    96 :  0 %\n",
      "Accuracy of    97 :  0 %\n",
      "Accuracy of    98 :  0 %\n",
      "Accuracy of    99 :  0 %\n",
      "Accuracy of   100 :  0 %\n",
      "Accuracy of   101 :  0 %\n",
      "Accuracy of   102 :  0 %\n",
      "Accuracy of   103 :  0 %\n",
      "Accuracy of   104 :  0 %\n",
      "Accuracy of   105 :  0 %\n",
      "Accuracy of   106 :  0 %\n",
      "Accuracy of   107 :  0 %\n",
      "Accuracy of   108 :  0 %\n",
      "Accuracy of   109 :  1 %\n",
      "Accuracy of   110 :  0 %\n",
      "Accuracy of   111 :  0 %\n",
      "Accuracy of   112 :  0 %\n",
      "Accuracy of   113 : 52 %\n",
      "Accuracy of   114 :  0 %\n",
      "Accuracy of   115 :  0 %\n",
      "Accuracy of   116 :  0 %\n",
      "Accuracy of   117 :  0 %\n",
      "Accuracy of   118 :  0 %\n",
      "Accuracy of   119 :  0 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(120))\n",
    "class_total = list(0. for i in range(120))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(120):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
