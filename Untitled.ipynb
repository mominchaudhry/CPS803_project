{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(verbose=False):\n",
    "    rootDir = 'Images'\n",
    "    images = np.zeros((1, 1280), dtype=np.uint8)\n",
    "    labels = np.empty(20580, dtype=object)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    sift = cv2.SIFT_create(10)\n",
    "    for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "        #print('Found directory: %s' % dirName)\n",
    "        if dirName != 'Images':\n",
    "            l = dirName.split('-')\n",
    "            label = l[1]\n",
    "#             if j == 5:\n",
    "#                 break\n",
    "            j += 1\n",
    "            print(label, j)\n",
    "        count = 0\n",
    "        for fname in fileList:\n",
    "            if dirName != 'Images':\n",
    "                img = cv2.imread(dirName + '/' + fname, 1)\n",
    "                file = open(\"Annotation\\\\\" + dirName.replace('Images\\\\', '') + \"\\\\\" + fname.replace('.jpg', '')).read()\n",
    "                bnd = [s.strip() for s in re.findall(r'<bndbox>(.*)</bndbox>', file, re.DOTALL)][0].replace('<', ' ').replace('>', ' ').split()\n",
    "                bndbox = [bnd[1], bnd[4], bnd[7], bnd[10]]\n",
    "                im3 = img[int(bndbox[1]):int(bndbox[3]), int(bndbox[0]):int(bndbox[2])]\n",
    "                im = Image.fromarray(im3)\n",
    "                im.save(dirName + '/' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chihuahua 1\n",
      "Japanese_spaniel 2\n",
      "Maltese_dog 3\n",
      "Pekinese 4\n",
      "Shih_Tzu 5\n",
      "Blenheim_spaniel 6\n",
      "papillon 7\n",
      "toy_terrier 8\n",
      "Rhodesian_ridgeback 9\n",
      "Afghan_hound 10\n",
      "basset 11\n",
      "beagle 12\n",
      "bloodhound 13\n",
      "bluetick 14\n",
      "black_and_tan_coonhound 15\n",
      "Walker_hound 16\n",
      "English_foxhound 17\n",
      "redbone 18\n",
      "borzoi 19\n",
      "Irish_wolfhound 20\n",
      "Italian_greyhound 21\n",
      "whippet 22\n",
      "Ibizan_hound 23\n",
      "Norwegian_elkhound 24\n",
      "otterhound 25\n",
      "Saluki 26\n",
      "Scottish_deerhound 27\n",
      "Weimaraner 28\n",
      "Staffordshire_bullterrier 29\n",
      "American_Staffordshire_terrier 30\n",
      "Bedlington_terrier 31\n",
      "Border_terrier 32\n",
      "Kerry_blue_terrier 33\n",
      "Irish_terrier 34\n",
      "Norfolk_terrier 35\n",
      "Norwich_terrier 36\n",
      "Yorkshire_terrier 37\n",
      "wire_haired_fox_terrier 38\n",
      "Lakeland_terrier 39\n",
      "Sealyham_terrier 40\n",
      "Airedale 41\n",
      "cairn 42\n",
      "Australian_terrier 43\n",
      "Dandie_Dinmont 44\n",
      "Boston_bull 45\n",
      "miniature_schnauzer 46\n",
      "giant_schnauzer 47\n",
      "standard_schnauzer 48\n",
      "Scotch_terrier 49\n",
      "Tibetan_terrier 50\n",
      "silky_terrier 51\n",
      "soft_coated_wheaten_terrier 52\n",
      "West_Highland_white_terrier 53\n",
      "Lhasa 54\n",
      "flat_coated_retriever 55\n",
      "curly_coated_retriever 56\n",
      "golden_retriever 57\n",
      "Labrador_retriever 58\n",
      "Chesapeake_Bay_retriever 59\n",
      "German_short_haired_pointer 60\n",
      "vizsla 61\n",
      "English_setter 62\n",
      "Irish_setter 63\n",
      "Gordon_setter 64\n",
      "Brittany_spaniel 65\n",
      "clumber 66\n",
      "English_springer 67\n",
      "Welsh_springer_spaniel 68\n",
      "cocker_spaniel 69\n",
      "Sussex_spaniel 70\n",
      "Irish_water_spaniel 71\n",
      "kuvasz 72\n",
      "schipperke 73\n",
      "groenendael 74\n",
      "malinois 75\n",
      "briard 76\n",
      "kelpie 77\n",
      "komondor 78\n",
      "Old_English_sheepdog 79\n",
      "Shetland_sheepdog 80\n",
      "collie 81\n",
      "Border_collie 82\n",
      "Bouvier_des_Flandres 83\n",
      "Rottweiler 84\n",
      "German_shepherd 85\n",
      "Doberman 86\n",
      "miniature_pinscher 87\n",
      "Greater_Swiss_Mountain_dog 88\n",
      "Bernese_mountain_dog 89\n",
      "Appenzeller 90\n",
      "EntleBucher 91\n",
      "boxer 92\n",
      "bull_mastiff 93\n",
      "Tibetan_mastiff 94\n",
      "French_bulldog 95\n",
      "Great_Dane 96\n",
      "Saint_Bernard 97\n",
      "Eskimo_dog 98\n",
      "malamute 99\n",
      "Siberian_husky 100\n",
      "affenpinscher 101\n",
      "basenji 102\n",
      "pug 103\n",
      "Leonberg 104\n",
      "Newfoundland 105\n",
      "Great_Pyrenees 106\n",
      "Samoyed 107\n",
      "Pomeranian 108\n",
      "chow 109\n",
      "keeshond 110\n",
      "Brabancon_griffon 111\n",
      "Pembroke 112\n",
      "Cardigan 113\n",
      "toy_poodle 114\n",
      "miniature_poodle 115\n",
      "standard_poodle 116\n",
      "Mexican_hairless 117\n",
      "dingo 118\n",
      "dhole 119\n",
      "African_hunting_dog 120\n"
     ]
    }
   ],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Images.shape)\n",
    "# print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, test_x, train_y, test_y = train_test_split(Images, Labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.shape, train_y.shape)\n",
    "# print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 12000) (12000,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "mat = loadmat('train_data.mat')\n",
    "train_data = mat['train_data']\n",
    "train_labels = mat['train_info'][0, 0]['labels'].reshape(12000, )\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='precomputed')\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = loadmat('test_data.mat')\n",
    "test_data = mat1['test_data']\n",
    "test_labels = mat1['test_info'][0, 0]['labels'].reshape(len(test_data), )\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test_data)\n",
    "print(preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, preds)\n",
    "np.savetxt('confusion.txt', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "CNN BELOW\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x000001D858FA7E20> <torch.utils.data.dataset.Subset object at 0x000001D85A1D5E20>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "data = torchvision.datasets.ImageFolder(root='Images', transform=trans)\n",
    "traindata, testdata = torch.utils.data.random_split(data, [12000, 8580])\n",
    "print(traindata, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001D859055D90> <torch.utils.data.dataloader.DataLoader object at 0x000001D85A17C550>\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=4)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size = 4)\n",
    "print(trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 29*29, 240)\n",
    "        self.fc2 = nn.Linear(240, 120)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), 16*29*29)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 2.359\n",
      "[1,  2000] loss: 2.278\n",
      "[1,  3000] loss: 2.231\n",
      "[2,  1000] loss: 2.164\n",
      "[2,  2000] loss: 2.126\n",
      "[2,  3000] loss: 2.086\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8580 test images: 5 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 8580 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 :  0 %\n",
      "Accuracy of     1 :  3 %\n",
      "Accuracy of     2 :  0 %\n",
      "Accuracy of     3 :  0 %\n",
      "Accuracy of     4 :  9 %\n",
      "Accuracy of     5 : 46 %\n",
      "Accuracy of     6 :  0 %\n",
      "Accuracy of     7 : 17 %\n",
      "Accuracy of     8 :  1 %\n",
      "Accuracy of     9 : 27 %\n",
      "Accuracy of    10 :  0 %\n",
      "Accuracy of    11 :  0 %\n",
      "Accuracy of    12 :  2 %\n",
      "Accuracy of    13 :  3 %\n",
      "Accuracy of    14 : 21 %\n",
      "Accuracy of    15 :  5 %\n",
      "Accuracy of    16 :  2 %\n",
      "Accuracy of    17 :  0 %\n",
      "Accuracy of    18 :  0 %\n",
      "Accuracy of    19 :  5 %\n",
      "Accuracy of    20 :  0 %\n",
      "Accuracy of    21 :  1 %\n",
      "Accuracy of    22 :  0 %\n",
      "Accuracy of    23 :  0 %\n",
      "Accuracy of    24 :  0 %\n",
      "Accuracy of    25 :  0 %\n",
      "Accuracy of    26 :  0 %\n",
      "Accuracy of    27 :  0 %\n",
      "Accuracy of    28 :  0 %\n",
      "Accuracy of    29 :  2 %\n",
      "Accuracy of    30 : 24 %\n",
      "Accuracy of    31 :  0 %\n",
      "Accuracy of    32 :  1 %\n",
      "Accuracy of    33 :  0 %\n",
      "Accuracy of    34 : 19 %\n",
      "Accuracy of    35 :  0 %\n",
      "Accuracy of    36 :  0 %\n",
      "Accuracy of    37 : 10 %\n",
      "Accuracy of    38 :  0 %\n",
      "Accuracy of    39 : 31 %\n",
      "Accuracy of    40 :  7 %\n",
      "Accuracy of    41 :  0 %\n",
      "Accuracy of    42 : 11 %\n",
      "Accuracy of    43 :  9 %\n",
      "Accuracy of    44 :  0 %\n",
      "Accuracy of    45 :  0 %\n",
      "Accuracy of    46 :  0 %\n",
      "Accuracy of    47 :  0 %\n",
      "Accuracy of    48 :  0 %\n",
      "Accuracy of    49 :  5 %\n",
      "Accuracy of    50 :  0 %\n",
      "Accuracy of    51 :  0 %\n",
      "Accuracy of    52 : 18 %\n",
      "Accuracy of    53 :  1 %\n",
      "Accuracy of    54 :  0 %\n",
      "Accuracy of    55 :  8 %\n",
      "Accuracy of    56 :  0 %\n",
      "Accuracy of    57 :  0 %\n",
      "Accuracy of    58 :  1 %\n",
      "Accuracy of    59 :  2 %\n",
      "Accuracy of    60 :  0 %\n",
      "Accuracy of    61 :  1 %\n",
      "Accuracy of    62 : 13 %\n",
      "Accuracy of    63 :  0 %\n",
      "Accuracy of    64 :  0 %\n",
      "Accuracy of    65 :  0 %\n",
      "Accuracy of    66 :  1 %\n",
      "Accuracy of    67 :  0 %\n",
      "Accuracy of    68 :  0 %\n",
      "Accuracy of    69 :  3 %\n",
      "Accuracy of    70 : 15 %\n",
      "Accuracy of    71 :  0 %\n",
      "Accuracy of    72 : 39 %\n",
      "Accuracy of    73 : 47 %\n",
      "Accuracy of    74 :  0 %\n",
      "Accuracy of    75 :  0 %\n",
      "Accuracy of    76 :  0 %\n",
      "Accuracy of    77 :  0 %\n",
      "Accuracy of    78 :  5 %\n",
      "Accuracy of    79 :  1 %\n",
      "Accuracy of    80 :  1 %\n",
      "Accuracy of    81 :  9 %\n",
      "Accuracy of    82 :  1 %\n",
      "Accuracy of    83 : 10 %\n",
      "Accuracy of    84 :  0 %\n",
      "Accuracy of    85 :  0 %\n",
      "Accuracy of    86 :  0 %\n",
      "Accuracy of    87 : 16 %\n",
      "Accuracy of    88 :  0 %\n",
      "Accuracy of    89 : 28 %\n",
      "Accuracy of    90 : 13 %\n",
      "Accuracy of    91 :  0 %\n",
      "Accuracy of    92 :  0 %\n",
      "Accuracy of    93 :  0 %\n",
      "Accuracy of    94 :  0 %\n",
      "Accuracy of    95 :  0 %\n",
      "Accuracy of    96 :  0 %\n",
      "Accuracy of    97 :  0 %\n",
      "Accuracy of    98 :  0 %\n",
      "Accuracy of    99 :  4 %\n",
      "Accuracy of   100 :  0 %\n",
      "Accuracy of   101 :  4 %\n",
      "Accuracy of   102 :  0 %\n",
      "Accuracy of   103 :  9 %\n",
      "Accuracy of   104 :  0 %\n",
      "Accuracy of   105 : 14 %\n",
      "Accuracy of   106 : 12 %\n",
      "Accuracy of   107 :  4 %\n",
      "Accuracy of   108 : 43 %\n",
      "Accuracy of   109 :  4 %\n",
      "Accuracy of   110 :  6 %\n",
      "Accuracy of   111 :  0 %\n",
      "Accuracy of   112 :  0 %\n",
      "Accuracy of   113 :  0 %\n",
      "Accuracy of   114 :  0 %\n",
      "Accuracy of   115 :  0 %\n",
      "Accuracy of   116 :  6 %\n",
      "Accuracy of   117 :  0 %\n",
      "Accuracy of   118 :  0 %\n",
      "Accuracy of   119 : 25 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(120))\n",
    "class_total = list(0. for i in range(120))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(120):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
