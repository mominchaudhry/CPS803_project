{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_dataset(verbose=False):\n",
    "#     rootDir = 'Images'\n",
    "#     images = np.zeros((1, 1280), dtype=np.uint8)\n",
    "#     labels = np.empty(20580, dtype=object)\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     sift = cv2.SIFT_create(10)\n",
    "#     for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "#         #print('Found directory: %s' % dirName)\n",
    "#         if dirName != 'Images':\n",
    "#             l = dirName.split('-')\n",
    "#             label = l[1]\n",
    "# #             if j == 5:\n",
    "# #                 break\n",
    "#             j += 1\n",
    "#             print(label, j)\n",
    "#         count = 0\n",
    "#         for fname in fileList:\n",
    "#             if dirName != 'Images':\n",
    "#                 img = cv2.imread(dirName + '/' + fname, 0)\n",
    "#                 file = open(\"Annotation\\\\\" + dirName.replace('Images\\\\', '') + \"\\\\\" + fname.replace('.jpg', '')).read()\n",
    "#                 bnd = [s.strip() for s in re.findall(r'<bndbox>(.*)</bndbox>', file, re.DOTALL)][0].replace('<', ' ').replace('>', ' ').split()\n",
    "#                 bndbox = [bnd[1], bnd[4], bnd[7], bnd[10]]\n",
    "#                 im3 = img[int(bndbox[1]):int(bndbox[3]), int(bndbox[0]):int(bndbox[2])]\n",
    "#                 if verbose == True:\n",
    "#                     print(fname, i)\n",
    "#                 #im = cv2.resize(im3, dsize=(256, 256), interpolation=cv2.INTER_CUBIC).astype(np.uint8)\n",
    "#                 kp, des = sift.detectAndCompute(im3,None)\n",
    "# #                 winSize = (64,64)\n",
    "# #                 blockSize = (16,16)\n",
    "# #                 blockStride = (8,8)\n",
    "# #                 cellSize = (8,8)\n",
    "# #                 nbins = 9\n",
    "# #                 derivAperture = 1\n",
    "# #                 winSigma = 4.\n",
    "# #                 histogramNormType = 0\n",
    "# #                 L2HysThreshold = 2.0000000000000001e-01\n",
    "# #                 gammaCorrection = 0\n",
    "# #                 nlevels = 64\n",
    "# #                 hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "# #                                         histogramNormType,L2HysThreshold,gammaCorrection,nlevels)\n",
    "# #                 winStride = (8,8)\n",
    "# #                 padding = (8,8)\n",
    "# #                 locations = ((10,20),)\n",
    "# #                 hist = hog.compute(im,winStride,padding,locations)\n",
    "#                 imm = des[:10,:].flatten().reshape(1, 1280)\n",
    "#                 images = np.append(images, imm, axis=0)\n",
    "#                 labels[i] = label\n",
    "#                 i += 1\n",
    "# #                 if count >= 99:\n",
    "# #                     break\n",
    "# #                 count += 1\n",
    "#     return images[1:,:], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images, Labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Images.shape)\n",
    "# print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, test_x, train_y, test_y = train_test_split(Images, Labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.shape, train_y.shape)\n",
    "# print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 12000) (12000,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "mat = loadmat('train_data.mat')\n",
    "train_data = mat['train_data']\n",
    "train_labels = mat['train_info'][0, 0]['labels'].reshape(12000, )\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='precomputed')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='precomputed')\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8580, 12000) (8580,)\n"
     ]
    }
   ],
   "source": [
    "mat1 = loadmat('test_data.mat')\n",
    "test_data = mat1['test_data']\n",
    "test_labels = mat1['test_info'][0, 0]['labels'].reshape(len(test_data), )\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   1 ... 120  69 120]\n",
      "[  1   1   1 ... 120 120 120]\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_data)\n",
    "print(preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, preds)\n",
    "np.savetxt('confusion.txt', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18834498834498833"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x000002431EF40F40> <torch.utils.data.dataset.Subset object at 0x000002431F6ABB20>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "data = torchvision.datasets.ImageFolder(root='Images')\n",
    "traindata, testdata = torch.utils.data.random_split(data, [12000, 8580])\n",
    "print(traindata, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002431F6ABEE0> <torch.utils.data.dataloader.DataLoader object at 0x000002431F6ABAF0>\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traindata)\n",
    "testloader = torch.utils.data.DataLoader(testdata)\n",
    "print(trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
