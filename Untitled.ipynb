{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(verbose=False):\n",
    "    rootDir = 'Images'\n",
    "    images = np.zeros((1, 1280), dtype=np.uint8)\n",
    "    labels = np.empty(20580, dtype=object)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    sift = cv2.SIFT_create(10)\n",
    "    for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "        #print('Found directory: %s' % dirName)\n",
    "        if dirName != 'Images':\n",
    "            l = dirName.split('-')\n",
    "            label = l[1]\n",
    "#             if j == 5:\n",
    "#                 break\n",
    "            j += 1\n",
    "            print(label, j)\n",
    "        count = 0\n",
    "        for fname in fileList:\n",
    "            if dirName != 'Images':\n",
    "                img = cv2.imread(dirName + '/' + fname, 0)\n",
    "                file = open(\"Annotation\\\\\" + dirName.replace('Images\\\\', '') + \"\\\\\" + fname.replace('.jpg', '')).read()\n",
    "                bnd = [s.strip() for s in re.findall(r'<bndbox>(.*)</bndbox>', file, re.DOTALL)][0].replace('<', ' ').replace('>', ' ').split()\n",
    "                bndbox = [bnd[1], bnd[4], bnd[7], bnd[10]]\n",
    "                im3 = img[int(bndbox[1]):int(bndbox[3]), int(bndbox[0]):int(bndbox[2])]\n",
    "                if verbose == True:\n",
    "                    print(fname, i)\n",
    "                #im = cv2.resize(im3, dsize=(256, 256), interpolation=cv2.INTER_CUBIC).astype(np.uint8)\n",
    "                kp, des = sift.detectAndCompute(im3,None)\n",
    "#                 winSize = (64,64)\n",
    "#                 blockSize = (16,16)\n",
    "#                 blockStride = (8,8)\n",
    "#                 cellSize = (8,8)\n",
    "#                 nbins = 9\n",
    "#                 derivAperture = 1\n",
    "#                 winSigma = 4.\n",
    "#                 histogramNormType = 0\n",
    "#                 L2HysThreshold = 2.0000000000000001e-01\n",
    "#                 gammaCorrection = 0\n",
    "#                 nlevels = 64\n",
    "#                 hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "#                                         histogramNormType,L2HysThreshold,gammaCorrection,nlevels)\n",
    "#                 winStride = (8,8)\n",
    "#                 padding = (8,8)\n",
    "#                 locations = ((10,20),)\n",
    "#                 hist = hog.compute(im,winStride,padding,locations)\n",
    "                imm = des[:10,:].flatten().reshape(1, 1280)\n",
    "                images = np.append(images, imm, axis=0)\n",
    "                labels[i] = label\n",
    "                i += 1\n",
    "#                 if count >= 99:\n",
    "#                     break\n",
    "#                 count += 1\n",
    "    return images[1:,:], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chihuahua 1\n",
      "Japanese_spaniel 2\n",
      "Maltese_dog 3\n",
      "Pekinese 4\n",
      "Shih_Tzu 5\n",
      "Blenheim_spaniel 6\n",
      "papillon 7\n",
      "toy_terrier 8\n",
      "Rhodesian_ridgeback 9\n",
      "Afghan_hound 10\n",
      "basset 11\n",
      "beagle 12\n",
      "bloodhound 13\n",
      "bluetick 14\n",
      "black_and_tan_coonhound 15\n",
      "Walker_hound 16\n",
      "English_foxhound 17\n",
      "redbone 18\n",
      "borzoi 19\n",
      "Irish_wolfhound 20\n",
      "Italian_greyhound 21\n",
      "whippet 22\n",
      "Ibizan_hound 23\n",
      "Norwegian_elkhound 24\n",
      "otterhound 25\n",
      "Saluki 26\n",
      "Scottish_deerhound 27\n",
      "Weimaraner 28\n",
      "Staffordshire_bullterrier 29\n",
      "American_Staffordshire_terrier 30\n",
      "Bedlington_terrier 31\n",
      "Border_terrier 32\n",
      "Kerry_blue_terrier 33\n",
      "Irish_terrier 34\n",
      "Norfolk_terrier 35\n",
      "Norwich_terrier 36\n",
      "Yorkshire_terrier 37\n",
      "wire_haired_fox_terrier 38\n",
      "Lakeland_terrier 39\n",
      "Sealyham_terrier 40\n",
      "Airedale 41\n",
      "cairn 42\n",
      "Australian_terrier 43\n",
      "Dandie_Dinmont 44\n",
      "Boston_bull 45\n",
      "miniature_schnauzer 46\n",
      "giant_schnauzer 47\n",
      "standard_schnauzer 48\n",
      "Scotch_terrier 49\n",
      "Tibetan_terrier 50\n",
      "silky_terrier 51\n",
      "soft_coated_wheaten_terrier 52\n",
      "West_Highland_white_terrier 53\n",
      "Lhasa 54\n",
      "flat_coated_retriever 55\n",
      "curly_coated_retriever 56\n",
      "golden_retriever 57\n",
      "Labrador_retriever 58\n",
      "Chesapeake_Bay_retriever 59\n",
      "German_short_haired_pointer 60\n",
      "vizsla 61\n",
      "English_setter 62\n",
      "Irish_setter 63\n",
      "Gordon_setter 64\n",
      "Brittany_spaniel 65\n",
      "clumber 66\n",
      "English_springer 67\n",
      "Welsh_springer_spaniel 68\n",
      "cocker_spaniel 69\n",
      "Sussex_spaniel 70\n",
      "Irish_water_spaniel 71\n",
      "kuvasz 72\n",
      "schipperke 73\n",
      "groenendael 74\n",
      "malinois 75\n",
      "briard 76\n",
      "kelpie 77\n",
      "komondor 78\n",
      "Old_English_sheepdog 79\n",
      "Shetland_sheepdog 80\n",
      "collie 81\n",
      "Border_collie 82\n",
      "Bouvier_des_Flandres 83\n",
      "Rottweiler 84\n",
      "German_shepherd 85\n",
      "Doberman 86\n",
      "miniature_pinscher 87\n",
      "Greater_Swiss_Mountain_dog 88\n",
      "Bernese_mountain_dog 89\n",
      "Appenzeller 90\n",
      "EntleBucher 91\n",
      "boxer 92\n",
      "bull_mastiff 93\n",
      "Tibetan_mastiff 94\n",
      "French_bulldog 95\n",
      "Great_Dane 96\n",
      "Saint_Bernard 97\n",
      "Eskimo_dog 98\n",
      "malamute 99\n",
      "Siberian_husky 100\n",
      "affenpinscher 101\n",
      "basenji 102\n",
      "pug 103\n",
      "Leonberg 104\n",
      "Newfoundland 105\n",
      "Great_Pyrenees 106\n",
      "Samoyed 107\n",
      "Pomeranian 108\n",
      "chow 109\n",
      "keeshond 110\n",
      "Brabancon_griffon 111\n",
      "Pembroke 112\n",
      "Cardigan 113\n",
      "toy_poodle 114\n",
      "miniature_poodle 115\n",
      "standard_poodle 116\n",
      "Mexican_hairless 117\n",
      "dingo 118\n",
      "dhole 119\n",
      "African_hunting_dog 120\n"
     ]
    }
   ],
   "source": [
    "Images, Labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20580, 1280)\n",
      "(20580,)\n"
     ]
    }
   ],
   "source": [
    "print(Images.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(Images, Labels, test_size=0.20)\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16464, 1280) (16464,)\n",
      "(4116, 1280) (4116,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Airedale' 'Bernese_mountain_dog' 'Leonberg' ... 'Bernese_mountain_dog'\n",
      " 'Scottish_deerhound' 'Maltese_dog']\n",
      "['cocker_spaniel' 'Cardigan' 'bloodhound' ... 'Appenzeller' 'schipperke'\n",
      " 'Ibizan_hound']\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_x)\n",
    "print(preds)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('confusion.txt', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03328474246841594"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
